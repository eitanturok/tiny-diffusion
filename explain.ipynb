{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b81d0cd",
   "metadata": {},
   "source": [
    "# What are diffusion models?\n",
    "\n",
    "A diffusion model is a neural network that learns to add and remove noise to images.\n",
    "\n",
    "This consists of two core steps:\n",
    "* forward process: we gradually \\textit{add} noise to an image until you end up with pure noise\n",
    "* reverse process $p_\\theta$: we gradually \\textit{remove} noise from pure pure noise until you end up with an actual image\n",
    "\n",
    "When we add noise to images we do it in $T$ steps. We start with $x_0$, our original image. $x_1$ means we've added noise once, $x_2$ means we've added noise twice, and $x_t$ means we've added noise $t$ times.\n",
    "\n",
    "What's the best way to model this mathematically?\n",
    "\n",
    "Ho decided to model the forward pass as a Markov chain with transitions from $x_t$ to $x_{t+1}$ following a a multivariate Gaussian distribution:\n",
    "$$\n",
    "q(x_t | x_{t-1})\n",
    "=\n",
    "N(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t I)\n",
    "$$\n",
    "Since this is Markovian, we know\n",
    "$$\n",
    "q(x_1:T | x_0) = \\prod_{t=1}^T q(x_t | x_{t-1})\n",
    "$$\n",
    "\n",
    "Small Remarks:\n",
    "1. The $\\beta_t$'s determine how much noise we add and are pre-defined, chosen by the user.\n",
    "2. We choose to make the mean of $x_t$ the mean of $x_{t-1}$ scaled by $\\sqrt{1 - \\beta_t}$. The choice of $\\sqrt{1 - \\beta_t}$ allows the math to work out nicely. \n",
    "3. We choose to make the variance of $x_t$ simply $\\beta_t I$. Again, this is a modeling choice and was done for simplicity. Note that unlike the mean, the variance does not depend directly on the previous image $x_{t-1}$.\n",
    "3. Because we are adding Gaussian noise over and over again, if we do it for long enough ($T$ is sufficiently large), the final state $x_T$ should itself resemble a Gaussian distribution.\n",
    "4. To actually compute the expression $N(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t I)$ on a computer we sample $\\epsilon \\sim N(0, 1)^d$ as a $d$-dimensional standard normal and then do\n",
    "$x_t = \\sqrt{1 - \\beta_t} + \\sqrt{\\beta_t} * \\epsilon.$\n",
    "Remember, to change the variance of a normal variable, you multiply it by the square root of the value and to change the mean, you add that value to it.\n",
    "5. Why did Ho make this normal? Because the normal distribution has this amazing \"reparameterization\" properties that we want to take advantage of to make our computation faster/easier. (More on this later.) Also, because in the real-world many objects actually do have a normal distribution.\n",
    "6.  Why is this Markovian? Adding noise in step $t$ only really depends on the previously noised image $x_{t-1}$. How ever much noise we added to get image $x_{t-2}$ is irrelvant to $x_{t}$ since we already captured the noise from $x_{t-2}$ when we have the image $x_{t-1}$.\n",
    "\n",
    "\n",
    "Great, we have the quantity $q(x_t | x_{t-1})$. Who cares?\n",
    "\n",
    "The quantity $q(x_t | x_{t-1})$ itself is not so interesting but the closely related $q(x_{t-1} | x_t)$ is hugely important!\n",
    "\n",
    "\n",
    "$q(x_t | x_{t-1})$ is the forward process and the $q(x_{t-1} | x_t)$ process because \n",
    "\n",
    "If we can sample from $q(x_{t-1} | x_t)$, we will be able to recreate the true sample from a Gaussian noise input $x_T \\sim N(0, 1)$ (see small remark 3).\n",
    "\n",
    "|                   | Forward Process          | Reverse Process                                        |\n",
    "|-------------------|--------------------------|--------------------------------------------------------|\n",
    "| Meaning           | Add Noise                | Remove Noise                                           |\n",
    "| How to get it     | Fixed, user chooses this | We learn this                                          |\n",
    "| Equation          | $q(x_t \\| x_{t-1})$      | $q(x_{t-1} \\| x_t) \\approx p_\\theta(x_{t-1} \\| x_t)$   |\n",
    "| Tractable         | Yes                      | No                                                     |\n",
    "| Approximated      | No                       | Yes, by our neural network                             |\n",
    "| Algorithm Stage   | Training                 | Inference / Sampling                                   |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$q(x_1:T | x_0)$ tells us that given an original image $x_0$, how likely is it for us to have this particular sequence of noised images. That's cool, but not so useful. The quantity we really care about is $q(x_{t-1} | x_t)$. This tells us how to go from noisy images $x_t$ to less noisy images $x_{t-1}$. If we know the probability distribution of $q(x_{t-1} | x_t)$, then simply plug an image of pure noise for $x_T$ and $q(x_{t-1} | x_t)$ will tell us which of the millions of variations of $x_T$ have the great chance of being \"less\" noisy. To us all of these \"less\" noisy images would probably still look like random noise, but the model can help us to gradually remove noise over and over again until we get to an image with no more noise left -- this should be a realistic looking image. If we have $q(x_{t-1} | x_t)$, we can recovering an original image from pure noise, not from a noise-injected image, from thin air, pure nothingness. This is our image generation model!\n",
    "\n",
    "Let's compute $q(x_t | x_{t-1})$:\n",
    "$$\n",
    "q(x_t | x_{t-1})\n",
    "=\n",
    "\\frac{q(x_{t_1}, x_t)}{q_{x_{t-1}}}\n",
    "\\\\\n",
    "=\n",
    "q(x_t | x_{t_1})  \\frac{q(x_{t_1})}{q_{x_{t-1}}}\n",
    "\\\\\n",
    "=\n",
    "q(x_t | x_{t_1})  \\frac{q(x_{t_1})}{q_{x_{t-1}}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0b40a2",
   "metadata": {},
   "source": [
    "<!-- OLD\n",
    "The first term:\n",
    "$$\n",
    "\\frac{x_t}{1 - \\bar{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{\\sqrt{\\bar{\\alpha_t}}}\n",
    "    +\n",
    "    \\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{x_t}{(1 - \\bar{\\alpha_t})}\n",
    "\\Big[\n",
    "    \\frac{1}{\\sqrt{\\alpha_t}}{\\beta_t}\n",
    "    +\n",
    "    \\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\frac{x_t}{(1 - \\bar{\\alpha_t})}\n",
    "\\Big[\n",
    "    \\beta_t\n",
    "    +\n",
    "    \\alpha_t (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{x_t}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\beta_t}{(1 - \\bar{\\alpha_t})}\n",
    "    +\n",
    "    \\alpha_t  \\frac{1 - \\bar{\\alpha_{t-1}}}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{x_t}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\beta_t}{(1 - \\bar{\\alpha_t})}\n",
    "    +\n",
    "    \\frac{\\alpha_t}{1 - \\alpha_t}\n",
    "\\Big]\n",
    "$$\n",
    "This last line is wrong -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b728086",
   "metadata": {},
   "source": [
    "We know \n",
    "$$\n",
    "\\tilde{\\mu}(x_t, x_0)\n",
    "=\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{1 - \\bar{\\alpha_t}} x_0\n",
    "+\n",
    "\\frac{\\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}} x_t\n",
    "$$\n",
    "from equation (7) and we know\n",
    "$$\n",
    "x_t\n",
    "=\n",
    "\\sqrt{\\bar{\\alpha_t}} x_0 + \\sqrt{1 - \\bar{\\alpha_t}} \\epsilon\n",
    "\\\\\n",
    "x_0\n",
    "=1\n",
    "\\frac{1}{\\sqrt{\\bar{\\alpha_t}}} \\big( x_t - \\sqrt{1 - \\bar{\\alpha_t}} \\epsilon \\big)\n",
    "$$\n",
    "from equation(4) where $\\epsilon \\sim N(0, 1)$.\n",
    "\n",
    "Now let's rewrite $\\tilde{\\mu}$ in terms of just $x_t$ by replacing $x_0$ with our expression above:\n",
    "$$\n",
    "\\tilde{\\mu}(x_t, x_0)\n",
    "=\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{1 - \\bar{\\alpha_t}} x_0\n",
    "+\n",
    "\\frac{\\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}} x_t\n",
    "\\\\\n",
    "\\tilde{\\mu}(x_t)\n",
    "=\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{1 - \\bar{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{1}{\\sqrt{\\bar{\\alpha_t}}} \\big( x_t - \\sqrt{1 - \\bar{\\alpha_t}} \\epsilon \\big)    \n",
    "\\Big]\n",
    "+\n",
    "\\frac{\\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}} x_t\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{1 - \\bar{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{\\sqrt{\\bar{\\alpha_t}}}\n",
    "    +\n",
    "    \\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "-\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{1 - \\bar{\\alpha_t}}\n",
    "\\sqrt{1 - \\bar{\\alpha_t}} \\epsilon\n",
    "\\\\\n",
    "=\n",
    "C_1 + C_2\n",
    "$$\n",
    "where $C_1$ is the first term and $C_2$ is the second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19a6832",
   "metadata": {},
   "source": [
    "Now let's simplify each term separately. The first term:\n",
    "\n",
    "$$\n",
    "C_1\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{1 - \\bar{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{\\sqrt{\\bar{\\alpha_t}}}\n",
    "    +\n",
    "    \\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{1 - \\bar{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\beta_t}{\\sqrt{\\alpha_t}}\n",
    "    +\n",
    "    \\sqrt{\\alpha_t} (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{1 - \\bar{\\alpha_t}}\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\beta_t\n",
    "    +\n",
    "    \\alpha_t (1 - \\bar{\\alpha_{t-1}})\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\beta_t}{1 - \\bar{\\alpha_t}}\n",
    "    +\n",
    "    \\frac{\\alpha_t (1 - \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{\\beta_t + \\alpha_t (1 - \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{(1 - \\alpha_t) + (\\alpha_t - \\alpha_t \\bar{\\alpha_{t-1}})}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{1 - \\alpha_t \\bar{\\alpha_{t-1}}}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[\n",
    "    \\frac{1 - \\bar{\\alpha_t}}{1 - \\bar{\\alpha_t}}\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "x_t \n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c6fb0",
   "metadata": {},
   "source": [
    "Now the second term:\n",
    "$$\n",
    "C_2\n",
    "=\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}} \\beta_t}{1 - \\bar{\\alpha_t}}\n",
    "\\frac{1}{\\sqrt{\\bar{\\alpha_t}}}\n",
    "\\sqrt{1 - \\bar{\\alpha_t}} \\epsilon\n",
    "\\\\\n",
    "=\n",
    "\\beta_t \\epsilon\n",
    "\\frac{\\sqrt{\\bar{\\alpha_{t-1}}}}{\\sqrt{\\bar{\\alpha_t}}}\n",
    "\\frac{\\sqrt{1 - \\bar{\\alpha_t}}}{1 - \\bar{\\alpha_t}}\n",
    "\\\\\n",
    "=\n",
    "\\beta_t \\epsilon\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\frac{1}{\\sqrt{1 - \\bar{\\alpha_t}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd78ca",
   "metadata": {},
   "source": [
    "So putting it together, we get\n",
    "$$\n",
    "\\tilde{\\mu}(x_t)\n",
    "=\n",
    "C_1 + C_2\n",
    "\\\\\n",
    "=\n",
    "x_t \\frac{1}{\\sqrt{\\alpha_t}}\n",
    "+\n",
    "\\beta_t \\epsilon\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\frac{1}{\\sqrt{1 - \\bar{\\alpha_t}}}\n",
    "\\\\\n",
    "=\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[ \n",
    "    x_t + \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\epsilon\n",
    "\\Big]\n",
    "$$\n",
    "\n",
    "This last line is equation (11) in the paper and is used in step 4 of Algorithm 2 Sampling.\n",
    "\n",
    "What does this mean? We are simply taking our noisy image $x_t$ adding some scaled noise $\\epsilon$ to it\n",
    "\n",
    "This is great -- we no longer have $x_0$ in our equation for $\\tilde{\\mu}$. So we can predict the previous timestep, $x_{t-1}$ with only a dependence on $x_t$, not the initial, unnoised image. \n",
    "\n",
    "To go from a noisy image $x_{t}$ to a less noisy image $x_{t-1}$, we initially need the mean $\\tilde{\\mu}$ of $x_{t-1}$ to depend on $x_0$, the intitial, perfect, unnoised image. This is stupid. If are trying to repeatedly denoise random noise into an actual image, this is telling us we need that actual image $x_0$ to begin with! We can't do anything with this.\n",
    "\n",
    "So we need to reparameterize. We need a way to find $\\tilde{\\mu}$ without depending on $x_0$ explicitallly. Great, we've now done the re-parameterization, we no longer have $x_0$ in our equation. But where did all the info that $x_0$ gave us go? The answer: in the $\\bar{\\alpha_t}$ variable because this term contains the cumulative noise that we've repeatedly added ever since we started at $t=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c88d5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\tilde{\\mu_t}\n",
    "=\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[ \n",
    "    x_t + \\frac{\\beta_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\epsilon\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{1}{\\sqrt{\\alpha_t}}\n",
    "\\Big[ \n",
    "    x_t + \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha_t}}} \\epsilon\n",
    "\\Big]\n",
    "\\\\\n",
    "=\n",
    "\\frac{\\sqrt{1 - \\bar{\\alpha_t}}}{\\sqrt{\\alpha_t}}\n",
    "\\Big[ \n",
    "    \\sqrt{1 - \\bar{\\alpha_t}}x_t + (1 - \\alpha_t) \\epsilon\n",
    "\\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec11b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
